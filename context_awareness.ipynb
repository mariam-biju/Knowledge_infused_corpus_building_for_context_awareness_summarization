{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7RSnJsoqyyN",
    "outputId": "cdcf5c56-1f2c-4ecb-87d4-d9d97932b240"
   },
   "outputs": [],
   "source": [
    "# Install Transformers & Dataset Libraries\n",
    "!pip install transformers datasets torch nltk rouge_score -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LrCz0Z42vQFB",
    "outputId": "f2e5548c-1994-45dc-bad7-9ac774d8855a"
   },
   "outputs": [],
   "source": [
    "!pip install ir_datasets transformers datasets sentencepiece torch biopython -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLGrYMtXvVdo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MD6dNRSzvawI"
   },
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "\n",
    "# Load datasets\n",
    "trec_cds = ir_datasets.load(\"pmc/v1/trec-cds-2014\")\n",
    "\n",
    "# Extract documents\n",
    "trec_cds_docs = [{\"doc_id\": doc.doc_id, \"title\": doc.title, \"abstract\": doc.abstract} for doc in trec_cds.docs_iter()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O5lcWzjz-Kz7",
    "outputId": "226e6328-457e-4515-84ae-aa4447bf69dd"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "# Define the path where the uploaded tar.gz file is located\n",
    "tar_path = \"/content/ohsumed-first-20000-docs.tar.gz\"  # Update this if filename differs\n",
    "\n",
    "# Define the extraction path\n",
    "extract_path = \"/content/OHSUMED\"\n",
    "\n",
    "# Extract the tar.gz file\n",
    "with tarfile.open(tar_path, \"r:gz\") as tar:\n",
    "    tar.extractall(extract_path)\n",
    "\n",
    "print(\"‚úÖ Extraction complete! Files are in:\", extract_path)\n",
    "\n",
    "# List extracted files\n",
    "print(\"Extracted Files:\", os.listdir(extract_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H2_L-eSZ_cS0",
    "outputId": "ef58f2fa-36a2-42cb-89f9-f1a0a7d8e3fd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List files inside OHSUMED\n",
    "for root, dirs, files in os.walk(extract_path):\n",
    "    print(f\"üìÇ Folder: {root}\")\n",
    "    for file in files:\n",
    "        print(f\"  üìÑ File: {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K_ipYTJX_khk",
    "outputId": "d7a06844-2efe-4a69-9bb6-fd5e5d83b7e2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Root directory of the extracted OHSUMED dataset\n",
    "root_dir = \"/content/OHSUMED/ohsumed-first-20000-docs\"\n",
    "\n",
    "# Store extracted documents\n",
    "ohsumed_docs = []\n",
    "\n",
    "# Recursively walk through all folders and collect text files\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "\n",
    "        # Read content of each file\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                content = f.read().strip()\n",
    "\n",
    "                # Assuming first line is title, remaining is abstract\n",
    "                lines = content.split(\"\\n\")\n",
    "                doc_id = file  # Using filename as document ID\n",
    "                title = lines[0].strip() if len(lines) > 0 else \"Untitled\"\n",
    "                abstract = \" \".join(lines[1:]).strip() if len(lines) > 1 else \"No abstract available.\"\n",
    "\n",
    "                # Store document details\n",
    "                ohsumed_docs.append({\"doc_id\": doc_id, \"title\": title, \"abstract\": abstract})\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Skipping file {file_path}: {e}\")\n",
    "\n",
    "print(f\"‚úÖ Successfully loaded {len(ohsumed_docs)} documents from OHSUMED.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cC6EESEjAhKM",
    "outputId": "4ddce41a-b949-4bad-beb9-0516708e1e43"
   },
   "outputs": [],
   "source": [
    "# Merge OHSUMED and TREC CDS 2014 datasets\n",
    "documents = ohsumed_docs + trec_cds_docs\n",
    "\n",
    "print(f\"‚úÖ Total documents available: {len(documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "047d99178eed4a189ac86cc65587defb",
      "bbec278a6cef4487b88e1c0f07f52eec",
      "757da2389cb548c3bfbdfabbca07cef7",
      "631c9f14bc3b49ea977f36fd8da79946",
      "2affcba907144b8f8114a41cb4a68d5c",
      "9889dc25894e42bfb29555be871f1ea8",
      "bd850b4189724046b8ea2c6379f40669",
      "bc627ceea4ee47798f01b744e6eb86d8",
      "3b8d7cffd23345ccb6e32ef8cd1031bb",
      "d5fee93139e54e55af7546ca405d0e6b",
      "4ddf1c9e77784a09b3e6017804dd09cd",
      "6aa64a6e4eec47cf8bf8a080e7db70a7",
      "096c4dd0785b40c9ab3077a1f2ba6a59",
      "222cd785357041d29b7c70df44f6e336",
      "73d09c394e8e4c8ebfbbd5e83fe9f5fa",
      "93fa2fa057374a6892500222bbf3f5e5",
      "1477f7c998b64ad6a99b518c3c1b6706",
      "a1d14ef0cca0475ab351072501c5a936",
      "0fc06c8fd7724418b14504a91140c5b2",
      "e131dc4e69a94d8080263b90f7e61514",
      "423e4ec616924178ae2f8b8813183d7f",
      "b532fa4616754adba74bc818100cf627",
      "6a706a0aec524eb6a3e0621e665a88e5",
      "3be08ad700774e76bdfed37a18f8d131",
      "52b833430a4f49628334a9511242bc1a",
      "511ba893651547818dfdae8fd9c18bdf",
      "03bd6bcdac294ed7b7034e96215f8849",
      "d0c121bce87140a0bd3c7e3f506b91a5",
      "6e28aeae7c774183aec9b770e6390727",
      "0d47256da854411c8489ced563ff7866",
      "b870366298e74413a5387c0209f6f54b",
      "fad33c2ad6d647989023fee2be39f9f3",
      "265ab153e43d4b3690b586ce5a9fc191",
      "f6dfa21b281d4cca9afd13a582edb563",
      "d8b83f18fdf64d19bbbbdbfa63ffc31e",
      "2b5ce594554542a4a875ea73b03bb2ef",
      "de486ada27c744cb9ecd7e830caf5d4c",
      "3085e0ea77b5436a9eeebd094100661a",
      "fb06add62cb7458283025f307ca50e52",
      "7de000cfa61543c982bb65c0b208815f",
      "0eab742275c4497db547e00c6e82b24c",
      "2f4d0c497d334562b4827e037e1154d4",
      "5079f378523842f68ffe8bf5c9efbabc",
      "62fc384892af43d1a1f4c1ad996596cb",
      "e23a1d6f1cc9447ebdc8b3c3d7e2e26a",
      "33a2d441073942fc9d1197f7797dbd0f",
      "b34883f779094e05a7d6dd131ba14afc",
      "42f53536a9144f28bd5ac123acb8d5b9",
      "4036cc3dfec84a0092582086dfe9d857",
      "1a8186a8cfe5499aa8cb62c8accd04b4",
      "cedf40aee258426aa62315a540e04ee5",
      "08119bf0a9764f3dbdac5667d0e49d22",
      "23712289aaba42fc9227211e5c7a753a",
      "8b95b3dbe52343cfb65e535784dc6d4d",
      "b516a6cb758344149df626aa99ce45b9",
      "7fb81fc12dff43d18c8e40096fbac960",
      "f780a264ef454363b06fa53d4bb24306",
      "f900f551a1ce4957be9c9379b4576208",
      "f6c784cd44c54633aaec5bbe31dfda04",
      "b3a28fa51a344ccba6deaba4b7ce365a",
      "d4610c6a5bbb4b00a13f4e2771941d13",
      "57bec2a17de44ac7b599a829f786e310",
      "43e84f3617874cc3bb16c693a3999198",
      "ee06285cae6c4cb18c1a3ef3bdd52582",
      "684649e2ab2e47869e3d4da2ff4d919d",
      "8e48d885d90740658b3f65eca5cc3358"
     ]
    },
    "id": "FQZ4CS07Am7M",
    "outputId": "4dfdb50f-3387-48b9-f90f-12d9f7bc4e43"
   },
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "# Load BART tokenizer and model\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61WI52UUA8xU",
    "outputId": "f56fa0e7-919f-471c-cbdc-e28013bb1b21"
   },
   "outputs": [],
   "source": [
    "def summarize_text(text):\n",
    "    \"\"\"Generate an extractive summary using a BERT-based model.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"longest\", max_length=1024)\n",
    "    summary_ids = model.generate(**inputs, max_length=150, min_length=50, length_penalty=2.0, num_beams=4)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Summarize a few sample documents\n",
    "num_samples = 3  # Adjust as needed\n",
    "for i, doc in enumerate(documents[:num_samples]):\n",
    "    print(f\"\\nüîπ Document {i+1}: {doc['title']}\\n\")\n",
    "    print(f\"üìÑ Full Abstract:\\n{doc['abstract']}\\n\")\n",
    "\n",
    "    summary = summarize_text(doc[\"abstract\"])\n",
    "    print(f\"‚úÖ Extractive Summary:\\n{summary}\\n{'-'*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZj3wlt9BMUu",
    "outputId": "d9b1ebb0-1b74-4ea2-c5cf-b2c3bc53b5f4"
   },
   "outputs": [],
   "source": [
    "!pip install evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "9fddda2b8256471ea5899352618b61f9",
      "29eb9953498f4a38afcdb8ed1948922b",
      "8d4e7fa9234b4b10a152f227f52dd027",
      "8e4011448af94be88c0978642fb643e5",
      "f345d567c0f34352a31feb45911558e3",
      "89a48dee8dd74f1cbaaab8c3f37e604a",
      "9a6fdc98000c47148362ff04aee63a30",
      "fdf3ee3a3ca04c30b3ab78355b090f00",
      "6e928f80dc344ad88f459e827634881f",
      "2ad2c95947ae40769d86d1b9c673185e",
      "2be3fe277fea41e6b5f78439c223b8d6"
     ]
    },
    "id": "EXKLeVrKBoAk",
    "outputId": "c70c2b33-97ff-4eec-e58d-8c7784da024c"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Evaluate summaries\n",
    "references = [doc[\"abstract\"] for doc in documents[:3]]\n",
    "hypotheses = [summarize_text(doc[\"abstract\"]) for doc in documents[:3]]\n",
    "\n",
    "# Compute ROUGE scores\n",
    "results = rouge.compute(predictions=hypotheses, references=references)\n",
    "\n",
    "print(\"üîç ROUGE Scores:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhcUHOotCFhc"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch nltk rouge_score evaluate bert-extractive-summarizer -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "b6362064f43542dfbcb392ce52a79b23",
      "d1df8443365847e78e5d8a5fd1868d50",
      "1b94a16aa064465f87aae1ae5e089ff4",
      "58f0c975043444c987231a62f6206d6b",
      "47759085489847f59b421adf25bb91cc",
      "fbf96688b2814a49a90e14baefa46281",
      "49f3baacee3545e7977fb7a09ea8390c",
      "3422263b9e3049e2b62e4a4b1e92220e",
      "3cde29760b97445cbf3e771bd6ec46b3",
      "932fe8a96c9544d09d32f20da2528866",
      "1f22843a4c9f432494ddee70c36be250",
      "71cb3840339a4b21b0703e4d9320c06a",
      "03d3efbe831a4934ac780ba3937bde31",
      "7aac82707c344a6c9c7640920ede1642",
      "18207e6c92a64e218d3cf08bbc62be7d",
      "7a50cdb6617745c9b11deba25287e021",
      "f22f2219f02647db84acfef013cad43e",
      "ace9f3e52b3f48ac9aac7bc111198e91",
      "f95626a1b5ec41308c55dab74ff9e2c6",
      "4d7f686c9a994f41b682e817e05994fc",
      "33643960d1664636a931da3419b76a46",
      "2de98332efc54efba7891def2c89770f",
      "6e6a1d6af965478aadcdf1789e2d7b18",
      "c99dc081145c4fa4bfb5022f25e9cd2a",
      "2ba171af8bc94734b56d4399d82766ba",
      "d1d7f99685cf4434a7aec95f4c562aba",
      "8aad258529f04574851fe935f5b71cd5",
      "5ae1d71024cc43b5bc0c5f128797c013",
      "3bacc450a13249aeb3a60ed4016817fa",
      "e55964267f734be698f001d43e76d3eb",
      "1015a1288e2440dea7917e64c6aaf302",
      "e0c7b4428a5248ff9076f4329c719f38",
      "e00f4817819b49cda5356f1d63ad947a",
      "7be0fbfd21be4279b7490da4057f712c",
      "bffa0dcdca5b4d8ab488d5daaaac02fe",
      "e5257eba52804d04a9bfc9fbae897650",
      "be6560852a7f492496cb0e18494db8b4",
      "6604f69461264975b0b25f55875ccc78",
      "fc33d4d461b149369f5d2cf8aa1cd380",
      "9c3f89aaa2424e26a23948e34619e472",
      "a647d0ee6f784459a3b901ef7d00ca58",
      "b05e3f3b77b0460c8f151d4c1d7f04c4",
      "87ba10fe2d364d0bbff065fe8dc06f5f",
      "71a22304017e4a3fb1076a31ce3b8137",
      "af916ba0f50b4874b41583a17d1c943a",
      "f3544899b0d34d9f84e9ed6c5984251f",
      "8d00b76ef2f54ea9ae8ab6762249e6b6",
      "60cb095e8b914086b091147b32f51669",
      "336830c467be47f68ccc93e3c4935b93",
      "1bcb51a5bba846899af25c36c0a68a19",
      "a0128420b086408c9c5c3f858ddf4a5c",
      "66386fe0534e4ed1bc353629fdb5d86b",
      "bf41bc1f054c4fc0ab1049911a1ed5f5",
      "cc7cdf900fb942d8875ece619992b939",
      "fc3d8f235fa2467180994a70b2252428"
     ]
    },
    "id": "KHjhTGwXCIwc",
    "outputId": "c27f5c0b-5386-4e91-cf30-63fc85b595e0"
   },
   "outputs": [],
   "source": [
    "from summarizer import Summarizer\n",
    "\n",
    "# Load BERTSUMEXT Model\n",
    "bert_summarizer = Summarizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAJO-h5lCTCt",
    "outputId": "a08e6751-22dc-41a1-aa14-209a64864a3a"
   },
   "outputs": [],
   "source": [
    "def extractive_summarize(text, num_sentences=3):\n",
    "    \"\"\"\n",
    "    Extracts the top `num_sentences` sentences from the input text using BERTSUMEXT.\n",
    "    \"\"\"\n",
    "    summary = bert_summarizer(text, num_sentences=num_sentences)\n",
    "    return summary\n",
    "\n",
    "# Summarize a few sample abstracts\n",
    "num_samples = 4  # Change this to summarize more abstracts\n",
    "for i, doc in enumerate(documents[:num_samples]):\n",
    "    print(f\"\\nüîπ Document {i+1}: {doc['title']}\\n\")\n",
    "    print(f\"üìÑ Full Abstract:\\n{doc['abstract']}\\n\")\n",
    "\n",
    "    summary = extractive_summarize(doc[\"abstract\"])\n",
    "    print(f\"‚úÖ Extractive Summary:\\n{summary}\\n{'-'*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHs_GaDMCbRU",
    "outputId": "dda0a293-dd08-477e-bba0-df0268a2edb6"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# Load ROUGE metric\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "# Evaluate summaries\n",
    "references = [doc[\"abstract\"] for doc in documents[:num_samples]]\n",
    "hypotheses = [extractive_summarize(doc[\"abstract\"]) for doc in documents[:num_samples]]\n",
    "\n",
    "# Compute ROUGE scores\n",
    "results = rouge.compute(predictions=hypotheses, references=references)\n",
    "\n",
    "print(\"üîç ROUGE Scores:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
